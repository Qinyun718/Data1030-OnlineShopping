{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfOnline = pd.read_csv(\"../data/online_shoppers_intention.csv\")\n",
    "dfOnline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply MinMaxEncoder or StandardScaler on the continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "MinMax = pd.DataFrame(data = dfOnline[[\"Administrative_Duration\", \"Informational_Duration\", \"ProductRelated_Duration\"]])\n",
    "dfMinMax = pd.DataFrame(data = scaler1.fit_transform(MinMax))\n",
    "dfMinMax.columns = [\"Administrative_Duration\", \"Informational_Duration\", \"ProductRelated_Duration\"]\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "Standard = pd.DataFrame(data = dfOnline[[\"Administrative\" ,\"Informational\",\"ProductRelated\",\"PageValues\"]])\n",
    "dfStandard = pd.DataFrame(data = scaler2.fit_transform(Standard))\n",
    "dfStandard.columns = [\"Administrative\" ,\"Informational\",\"ProductRelated\",\"PageValues\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply OneHotEncoder or OrdinalEncoder on categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "dfOneHot = pd.DataFrame(dfOnline[[\"SpecialDay\",\"Month\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\", \"Weekend\"]])\n",
    "enc = OneHotEncoder(sparse=False,handle_unknown ='ignore' )\n",
    "allOneHot = enc.fit_transform(dfOneHot)\n",
    "colNames = list(enc.get_feature_names([\"SpecialDay\",\"Month\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\", \"Weekend\"]))\n",
    "dfOneHot_new = pd.DataFrame(data = allOneHot)\n",
    "dfOneHot_new.columns = colNames\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the LabelEncoder on the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "tar =  LabelEncoder()\n",
    "TaVar = list(dfOnline[\"Revenue\"])\n",
    "dfTaVar = pd.DataFrame(data = tar.fit_transform(TaVar))\n",
    "dfTaVar.columns = [\"Revenue\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unchanged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnchange = dfOnline[[\"BounceRates\",\"ExitRates\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the preprocessed data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [dfOneHot_new,dfMinMax,dfUnchange,dfStandard,dfTaVar]\n",
    "dfCombined = pd.concat(frames, axis = 1)\n",
    "dfCombined.head()\n",
    "dfCombined.to_csv('../data/prepocessedData.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpecialDay_0.0    0.000000\n",
      "SpecialDay_0.2    0.000000\n",
      "SpecialDay_0.4    0.000000\n",
      "SpecialDay_0.6    0.000000\n",
      "SpecialDay_0.8    0.000000\n",
      "                    ...   \n",
      "Administrative    0.001135\n",
      "Informational     0.001135\n",
      "ProductRelated    0.001135\n",
      "PageValues        0.000000\n",
      "Revenue           0.000000\n",
      "Length: 81, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(dfCombined.isnull().sum(axis=0)/dfCombined.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the percentage above, I notice that only small fraction of points contain missing values. Then, I did the MCAR test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006894233374809544\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as ma\n",
    "import scipy.stats as st\n",
    "\n",
    "def checks_input_mcar_tests(data):\n",
    "    \"\"\" Checks whether the input parameter of class McarTests is correct\n",
    "            Parameters\n",
    "            ----------\n",
    "            data:\n",
    "                The input of McarTests specified as 'data'\n",
    "            Returns\n",
    "            -------\n",
    "            bool\n",
    "                True if input is correct\n",
    "            \"\"\"\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        print(\"Error: Data should be a Pandas DataFrame\")\n",
    "        return False\n",
    "\n",
    "    if not any(data.dtypes.values == np.float):\n",
    "        if not any(data.dtypes.values == np.int):\n",
    "            print(\"Error: Dataset cannot contain other value types than floats and/or integers\")\n",
    "            return False\n",
    "\n",
    "    if not data.isnull().values.any():\n",
    "        print(\"Error: No NaN's in given data\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def mcar_test(data):\n",
    "    \"\"\" Implementation of Little's MCAR test\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas DataFrame\n",
    "        An incomplete dataset with samples as index and variables as columns\n",
    "    Returns\n",
    "    -------\n",
    "    p_value: Float\n",
    "        This value is the outcome of a chi-square statistical test, testing whether the null hypothesis\n",
    "        'the missingness mechanism of the incomplete dataset is MCAR' can be rejected.\n",
    "    \"\"\"\n",
    "\n",
    "    if not checks_input_mcar_tests(data):\n",
    "        raise Exception(\"Input not correct\")\n",
    "\n",
    "    dataset = data.copy()\n",
    "    vars = dataset.dtypes.index.values\n",
    "    n_var = dataset.shape[1]\n",
    "\n",
    "    # mean and covariance estimates\n",
    "    # ideally, this is done with a maximum likelihood estimator\n",
    "    gmean = dataset.mean()\n",
    "    gcov = dataset.cov()\n",
    "\n",
    "    # set up missing data patterns\n",
    "    r = 1 * dataset.isnull()\n",
    "    mdp = np.dot(r, list(map(lambda x: ma.pow(2, x), range(n_var))))\n",
    "    sorted_mdp = sorted(np.unique(mdp))\n",
    "    n_pat = len(sorted_mdp)\n",
    "    correct_mdp = list(map(lambda x: sorted_mdp.index(x), mdp))\n",
    "    dataset['mdp'] = pd.Series(correct_mdp, index=dataset.index)\n",
    "\n",
    "    # calculate statistic and df\n",
    "    pj = 0\n",
    "    d2 = 0\n",
    "    for i in range(n_pat):\n",
    "        dataset_temp = dataset.loc[dataset['mdp'] == i, vars]\n",
    "        select_vars = ~dataset_temp.isnull().any()\n",
    "        pj += np.sum(select_vars)\n",
    "        select_vars = vars[select_vars]\n",
    "        means = dataset_temp[select_vars].mean() - gmean[select_vars]\n",
    "        select_cov = gcov.loc[select_vars, select_vars]\n",
    "        mj = len(dataset_temp)\n",
    "        parta = np.dot(means.T, np.linalg.solve(select_cov, np.identity(select_cov.shape[1])))\n",
    "        d2 += mj * (np.dot(parta, means))\n",
    "\n",
    "    df = pj - n_var\n",
    "\n",
    "    # perform test and save output\n",
    "    p_value = 1 - st.chi2.cdf(d2, df)\n",
    "\n",
    "    return p_value\n",
    "\n",
    "\n",
    "print(mcar_test(dfCombined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From MCAR test, the p-value is aound 0.007 which is much smaller than 0.05. So, I decided to drop those observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12316, 81)\n"
     ]
    }
   ],
   "source": [
    "dfAfterDrop = dfCombined.dropna()\n",
    "print(dfAfterDrop.shape)\n",
    "dfAfterDrop.to_csv('../data/prepocessedData_Afterdrop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "##### The balance of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.84508\n",
      "1    0.15492\n",
      "Name: Revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = \"Revenue\"\n",
    "print(dfAfterDrop[label].value_counts()/dfAfterDrop[label].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
